{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84493,"databundleVersionId":11305158,"sourceType":"competition"},{"sourceId":10253875,"sourceType":"datasetVersion","datasetId":6297065},{"sourceId":207787842,"sourceType":"kernelVersion"},{"sourceId":214892435,"sourceType":"kernelVersion"},{"sourceId":216017958,"sourceType":"kernelVersion"},{"sourceId":216577393,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rtdl_num_embeddings -q --no-index --find-links=/kaggle/input/jane-street-import/rtdl_num_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T11:59:05.453722Z","iopub.execute_input":"2024-12-18T11:59:05.454096Z","iopub.status.idle":"2024-12-18T11:59:05.459053Z","shell.execute_reply.started":"2024-12-18T11:59:05.454061Z","shell.execute_reply":"2024-12-18T11:59:05.458029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import r2_score\nimport pandas as pd\nimport math\nimport numpy as np\nfrom tqdm import tqdm\nimport polars as pl\nfrom collections import OrderedDict\nimport sys\nfrom tanm_reference import Model, make_parameter_groups\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport kaggle_evaluation.jane_street_inference_server\n\nimport os\n\nimport joblib\n\nfrom pytorch_lightning import LightningModule","metadata":{"_uuid":"f573766f-0a4b-4a41-a873-d3e78e56afaf","_cell_guid":"8936e699-b090-4d2b-9bf2-b77f90fbefdb","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T11:59:05.462763Z","iopub.execute_input":"2024-12-18T11:59:05.463571Z","iopub.status.idle":"2024-12-18T11:59:09.668466Z","shell.execute_reply.started":"2024-12-18T11:59:05.46353Z","shell.execute_reply":"2024-12-18T11:59:09.66752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_list = [f\"feature_{idx:02d}\" for idx in range(79) if idx != 61]\n\ntarget_col = \"responder_6\" \n\nfeature_test = feature_list \\\n                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n\nfeature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\nfeature_cont = [item for item in feature_test if item not in feature_cat]\n\nbatch_size = 8192\n\nstd_feature = [i for i in feature_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n\ndata_stats = joblib.load(\"/kaggle/input/jane-street-data-preprocessing/data_stats.pkl\")\nmeans = data_stats['mean']\nstds = data_stats['std']\n\ndef standardize(df, feature_cols, means, stds):\n    return df.with_columns([\n        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n    ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T11:59:18.112962Z","iopub.execute_input":"2024-12-18T11:59:18.113316Z","iopub.status.idle":"2024-12-18T11:59:18.122229Z","shell.execute_reply.started":"2024-12-18T11:59:18.113284Z","shell.execute_reply":"2024-12-18T11:59:18.121405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"category_mappings = {'feature_09': {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21},\n 'feature_10': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8},\n 'feature_11': {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13,\n  76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30},\n 'symbol_id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19,\n  20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38},\n 'time_id' : {i : i for i in range(968)}}\n\ndef encode_column(df, column, mapping):\n    max_value = max(mapping.values())  \n\n    def encode_category(category):\n        return mapping.get(category, max_value + 1)  \n    \n    return df.with_columns(\n        pl.col(column).map_elements(encode_category).alias(column)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T11:59:21.369773Z","iopub.execute_input":"2024-12-18T11:59:21.370123Z","iopub.status.idle":"2024-12-18T11:59:21.379596Z","shell.execute_reply.started":"2024-12-18T11:59:21.370095Z","shell.execute_reply":"2024-12-18T11:59:21.378586Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TabM","metadata":{}},{"cell_type":"code","source":"class R2Loss(nn.Module):\n    def __init__(self):\n        super(R2Loss, self).__init__()\n\n    def forward(self, y_pred, y_true):\n        mse_loss = torch.sum((y_pred - y_true) ** 2)\n        var_y = torch.sum(y_true ** 2)\n        loss = mse_loss / (var_y + 1e-38)\n        return loss\n\nclass NN(LightningModule):\n    def __init__(self, n_cont_features, cat_cardinalities, n_classes, lr, weight_decay):\n        super().__init__()\n        self.save_hyperparameters()\n        self.k = 16\n        self.model = Model(\n                n_num_features=n_cont_features,\n                cat_cardinalities=cat_cardinalities,\n                n_classes=n_classes,\n                backbone={\n                    'type': 'MLP',\n                    'n_blocks': 3 ,\n                    'd_block': 512,\n                    'dropout': 0.25,\n                },\n                bins=None,\n                num_embeddings= None,\n                arch_type='tabm',\n                k=self.k,\n            )\n        self.lr = lr\n        self.weight_decay = weight_decay\n        self.training_step_outputs = []\n        self.validation_step_outputs = []\n        self.loss_fn = R2Loss()\n        # self.loss_fn = weighted_mse_loss\n\n    def forward(self, x_cont, x_cat):\n        return self.model(x_cont, x_cat).squeeze(-1)\n\n    def training_step(self, batch):\n        x_cont,x_cat, y, w , w_y= batch\n        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n        y_hat = self(x_cont, x_cat)\n        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n        self.training_step_outputs.append((y_hat.mean(1), y, w))\n        return loss\n\n    def validation_step(self, batch):\n        x_cont,x_cat, y, w, w_y = batch\n        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n        y_hat = self(x_cont, x_cat)\n        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n        self.validation_step_outputs.append((y_hat.mean(1), y, w))\n        return loss\n\n    def on_validation_epoch_end(self):\n        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n        if self.trainer.sanity_checking:\n            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n        else:\n            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n            # r2_val\n            val_r_square = r2_val(y, prob, weights)\n            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n        self.validation_step_outputs.clear()\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.lr, weight_decay=self.weight_decay)\n        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5,\n        #                                                        verbose=True)\n        return {\n            'optimizer': optimizer,\n            # 'lr_scheduler': {\n            #     'scheduler': scheduler,\n            #     'monitor': 'val_r_square',\n            # }\n        }\n\n    def on_train_epoch_end(self):\n        if self.trainer.sanity_checking:\n            return\n\n        y = torch.cat([x[1] for x in self.training_step_outputs]).cpu().numpy()\n        prob = torch.cat([x[0] for x in self.training_step_outputs]).detach().cpu().numpy()\n        weights = torch.cat([x[2] for x in self.training_step_outputs]).cpu().numpy()\n        # r2_training\n        train_r_square = r2_val(y, prob, weights)\n        self.log(\"train_r_square\", train_r_square, prog_bar=True, on_step=False, on_epoch=True)\n        self.training_step_outputs.clear()\n\n        epoch = self.trainer.current_epoch\n        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n        print(f\"Epoch {epoch}: {formatted_metrics}\")\n        \nclass custom_args():\n    def __init__(self):\n        self.usegpu = True\n        self.gpuid = 0\n        self.seed = 42\n        self.model = 'nn'\n        self.use_wandb = False\n        self.project = 'js-tabm-with-lags'\n        self.dname = \"./input_df/\"\n        self.loader_workers = 10   \n        self.bs = 8192\n        self.lr = 1e-3\n        self.weight_decay = 8e-4\n        self.n_cont_features = 84\n        self.n_cat_features = 5\n        self.n_classes = None\n        self.cat_cardinalities = [23, 10, 32, 40, 969]\n        self.patience = 7\n        self.max_epochs = 10\n        self.N_fold = 5\n\n\nmy_args = custom_args()\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nmodel = NN.load_from_checkpoint('/kaggle/input/my-own-js/tabm_epochepoch03.ckpt').to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:00:03.868917Z","iopub.execute_input":"2024-12-18T12:00:03.869428Z","iopub.status.idle":"2024-12-18T12:00:03.95425Z","shell.execute_reply.started":"2024-12-18T12:00:03.869394Z","shell.execute_reply":"2024-12-18T12:00:03.953532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lags_ : pl.DataFrame | None = None\n\nlags_history = None\n\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    global lags_, lags_history\n    if lags is not None:\n        lags_ = lags\n    \n    for col in feature_cat + ['symbol_id', 'time_id']:\n        test = encode_column(test, col, category_mappings[col])\n\n    predictions = test.select(\n        'row_id',\n        pl.lit(0.0).alias('responder_6'),\n    )\n    \n    symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n\n    time_id = test.select(\"time_id\").to_numpy()[0]\n    timie_id_array = test.select(\"time_id\").to_numpy()[:, 0]\n    \n    \n    if time_id == 0:\n        lags = lags.with_columns(pl.col('time_id').cast(pl.Int64))\n        lags = lags.with_columns(pl.col('symbol_id').cast(pl.Int64))\n    \n        lags_history = lags\n        lags = lags.filter(pl.col(\"time_id\") == 0)\n        \n        \n        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n    else:\n        lags = lags_history.filter(pl.col(\"time_id\") == time_id)\n        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n\n    \n    test = test.with_columns([\n        pl.col(col).fill_null(0) for col in feature_list + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n    ])\n\n    test = standardize(test, std_feature, means, stds)\n\n\n    X_test = test[feature_test].to_numpy()\n    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n\n    symbol_tensor = torch.tensor(symbol_ids, dtype=torch.float32).to(device)\n    time_tensor = torch.tensor(timie_id_array, dtype=torch.float32).to(device)\n    X_cat = X_test_tensor[:, [9, 10, 11]]\n    X_cont = X_test_tensor[:, [i for i in range(X_test_tensor.shape[1]) if i not in [9, 10, 11]]]\n    # X_cont = X_cont + torch.randn_like(X_cont) * 0.02\n\n    X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1), time_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n    \n\n    model.eval()\n    with torch.no_grad():\n        \n        outputs = model(X_cont, X_cat)\n        # Assuming the model outputs a tensor of shape (batch_size, 1)\n        preds = outputs.squeeze(-1).cpu().numpy()\n        preds = preds.mean(1)\n    \n    \n    predictions = \\\n    test.select('row_id').\\\n    with_columns(\n        pl.Series(\n            name   = 'responder_6', \n            values = np.clip(preds, a_min = -5, a_max = 5),\n            dtype  = pl.Float64,\n        )\n    )\n\n\n    # The predict function must return a DataFrame\n    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n    # with columns 'row_id', 'responer_6'\n    assert list(predictions.columns) == ['row_id', 'responder_6']\n    # and as many rows as the test data.\n    assert len(predictions) == len(test)\n\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:09:52.898738Z","iopub.execute_input":"2024-12-18T12:09:52.899194Z","iopub.status.idle":"2024-12-18T12:09:52.911272Z","shell.execute_reply.started":"2024-12-18T12:09:52.899159Z","shell.execute_reply":"2024-12-18T12:09:52.91035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nEVAL = False\nif EVAL:\n    test_dir = '/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/test.parquet'\n    lags_dir = '/kaggle/input/janestreet-updated-simulator-for-time-series-api/debug/lags.parquet'\nelse:\n    test_dir = '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet'\n    lags_dir = '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet'\n\ninference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            test_dir,\n            lags_dir\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:09:54.631865Z","iopub.execute_input":"2024-12-18T12:09:54.632262Z","iopub.status.idle":"2024-12-18T12:12:37.761Z","shell.execute_reply.started":"2024-12-18T12:09:54.632229Z","shell.execute_reply":"2024-12-18T12:12:37.760107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def weighted_zero_mean_r2(y_true, y_pred, weights):\n    \"\"\"\n    Calculate the sample weighted zero-mean R-squared score.\n\n    Parameters:\n    y_true (numpy.ndarray): Ground-truth values for responder_6.\n    y_pred (numpy.ndarray): Predicted values for responder_6.\n    weights (numpy.ndarray): Sample weight vector.\n\n    Returns:\n    float: The weighted zero-mean R-squared score.\n    \"\"\"\n    numerator = np.sum(weights * (y_true - y_pred)**2)\n    denominator = np.sum(weights * y_true**2)\n    \n    r2_score = 1 - numerator / denominator\n    return r2_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T11:59:22.070957Z","iopub.execute_input":"2024-12-18T11:59:22.07125Z","iopub.status.idle":"2024-12-18T11:59:22.07602Z","shell.execute_reply.started":"2024-12-18T11:59:22.071223Z","shell.execute_reply":"2024-12-18T11:59:22.07506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if EVAL:\n\n    submission_file = pd.read_parquet('/kaggle/working/submission.parquet')\n    y_pred = submission_file['responder_6']\n    \n    valid_df = pl.read_parquet(\"/kaggle/input/janestreet-updated-simulator-for-time-series-api/valid_df.parquet\")\n    \n    y_true = valid_df.select(\"responder_6\").to_numpy().reshape(-1)\n    \n    weights = valid_df.select(\"weight\").to_numpy().reshape(-1)\n    \n    print(weighted_zero_mean_r2(y_true, y_pred, weights))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T11:59:22.077007Z","iopub.execute_input":"2024-12-18T11:59:22.07726Z","iopub.status.idle":"2024-12-18T11:59:22.086945Z","shell.execute_reply.started":"2024-12-18T11:59:22.077234Z","shell.execute_reply":"2024-12-18T11:59:22.086108Z"}},"outputs":[],"execution_count":null}]}