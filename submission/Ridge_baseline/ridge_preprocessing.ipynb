{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge with Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# 1. Custom metric (weighted R², Kaggle-style)\n",
    "# ------------------------------\n",
    "def custom_metric(y_true, y_pred, weight):\n",
    "    return 1 - (np.sum(weight * (y_true - y_pred) ** 2) / np.sum(weight * y_true ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 2. Hand-rolled Preprocessor\n",
    "# =========================================================\n",
    "class RobustPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Hand-rolled preprocessing:\n",
    "    - Fill NaNs with median\n",
    "    - Robust scaling (median/IQR)\n",
    "    - Winsorization (clip to quantiles)\n",
    "    \"\"\"\n",
    "    def __init__(self, clip_quantiles=(0.01, 0.99)):\n",
    "        self.clip_quantiles = clip_quantiles\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        \n",
    "        # --- NaN-safe statistics ---\n",
    "        self.medians_ = np.nanmedian(X, axis=0)  # median per feature, ignoring NaNs\n",
    "        q75 = np.nanpercentile(X, 75, axis=0)\n",
    "        q25 = np.nanpercentile(X, 25, axis=0)\n",
    "        self.iqrs_ = q75 - q25\n",
    "        self.iqrs_[self.iqrs_ == 0] = 1e-6  # avoid div by zero\n",
    "        \n",
    "        # Winsorization bounds\n",
    "        self.lowers_ = np.nanpercentile(X, self.clip_quantiles[0]*100, axis=0)\n",
    "        self.uppers_ = np.nanpercentile(X, self.clip_quantiles[1]*100, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=np.float64).copy()\n",
    "        \n",
    "        # --- Step 1: Fill NaNs with training medians ---\n",
    "        mask = np.isnan(X)\n",
    "        if mask.any():\n",
    "            med = np.broadcast_to(self.medians_, X.shape)\n",
    "            X[mask] = med[mask]\n",
    "        \n",
    "        # --- Step 2: Robust scaling (median/IQR) ---\n",
    "        X = (X - self.medians_) / self.iqrs_\n",
    "        \n",
    "        # --- Step 3: Winsorization (clip extremes) ---\n",
    "        X = np.clip(X, self.lowers_, self.uppers_)\n",
    "        \n",
    "        # --- Final safety check: replace any leftover weird values ---\n",
    "        X = np.nan_to_num(X, nan=0.0, posinf=10.0, neginf=-10.0)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< read parquet >\n",
      "train.shape: (24205450, 91)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 3. Load training partitions\n",
    "# ------------------------------\n",
    "print(\"< read parquet >\")\n",
    "datas = []\n",
    "weights = []\n",
    "\n",
    "for i in range(6, 10):  # partitions 6–9\n",
    "    train = pl.read_parquet(\n",
    "        f\"/Users/apple/Masters/Job/kaggle/jane-street-real-time-market-data-forecasting/train.parquet/partition_id={i}/part-0.parquet\"\n",
    "    )\n",
    "    train = train.to_pandas().sample(frac=0.97, random_state=2025)\n",
    "\n",
    "    weights += list(train[\"weight\"].values)\n",
    "    train.drop([\"weight\"], axis=1, inplace=True)\n",
    "    datas.append(train)\n",
    "\n",
    "train = pd.concat(datas)\n",
    "del datas\n",
    "gc.collect()\n",
    "print(f\"train.shape: {train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 4. Features and target\n",
    "# ------------------------------\n",
    "cols = [f\"feature_0{i}\" if i < 10 else f\"feature_{i}\" for i in range(79)]\n",
    "X = train[cols].values\n",
    "y = train[\"responder_6\"].values\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape: (23805450, 79), test_X.shape: (400000, 79)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 5. Train/validation split\n",
    "# ------------------------------\n",
    "split = 400000  # around 2%\n",
    "train_X, test_X = X[:-split], X[-split:]\n",
    "train_y, test_y = y[:-split], y[-split:]\n",
    "train_weight, test_weight = weights[:-split], weights[-split:]\n",
    "\n",
    "print(f\"train_X.shape: {train_X.shape}, test_X.shape: {test_X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 6. Build preprocessing + Ridge pipeline\n",
    "# ------------------------------\n",
    "pipeline = Pipeline([\n",
    "    (\"pre\", RobustPreprocessor()),   # Step 1–3 preprocessing\n",
    "    (\"ridge\", Ridge(solver=\"saga\", alpha=1.0, random_state=0, max_iter=5000))  # Ridge regression\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< fit and predict >\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 7. Fit model\n",
    "# ------------------------------\n",
    "print(\"< fit and predict >\")\n",
    "pipeline.fit(train_X, train_y, ridge__sample_weight=train_weight)\n",
    "\n",
    "train_pred = pipeline.predict(train_X)\n",
    "test_pred = pipeline.predict(test_X)\n",
    "\n",
    "print(f\"train weighted_r2: {custom_metric(train_y, train_pred, weight=train_weight)}\")\n",
    "print(f\"test weighted_r2: {custom_metric(test_y, test_pred, weight=test_weight)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 8. Prediction on Test Data\n",
    "# =========================================================\n",
    "def predict(test_df, lags_df):\n",
    "    X_test = test_df[cols].to_numpy(dtype=np.float64)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    return pd.DataFrame({\"row_id\": test_df[\"row_id\"], \"responder_6\": preds})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 9. Load test data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_parquet(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/apple/Masters/Job/kaggle/jane-street-real-time-market-data-forecasting/test.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m lags_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/apple/Masters/Job/kaggle/jane-street-real-time-market-data-forecasting/lags.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# 9. Load test data\n",
    "# ------------------------------\n",
    "test_data = pd.read_parquet(\n",
    "    \"/Users/apple/Masters/Job/kaggle/jane-street-real-time-market-data-forecasting/test.parquet\",\n",
    "    engine=\"fastparquet\",\n",
    ")\n",
    "lags_data = pd.read_parquet(\n",
    "    \"/Users/apple/Masters/Job/kaggle/jane-street-real-time-market-data-forecasting/lags.parquet\",\n",
    "    engine=\"fastparquet\",\n",
    ")\n",
    "\n",
    "test_data[\"date_id\"] = test_data[\"date_id\"].astype(\"int32\")\n",
    "lags_data[\"date_id\"] = lags_data[\"date_id\"].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 10. Run final prediction\n",
    "# ------------------------------\n",
    "final_predictions = predict(test_data, lags_data)\n",
    "\n",
    "print(\"Prediction DataFrame:\")\n",
    "print(final_predictions.head())\n",
    "\n",
    "final_predictions.to_csv(\"ridge_predictions_preprocessed.csv\", index=False)\n",
    "print(\"Predictions saved to ridge_predictions_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
