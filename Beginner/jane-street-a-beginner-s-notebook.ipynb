{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mainly for model training\n",
    "\n",
    "Depending on the size of your training set, you will need an [inference notebook](https://www.kaggle.com/code/regisvargas/inference-jane-street-a-beginner-s-notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:13:37.265568Z",
     "iopub.status.busy": "2024-12-05T01:13:37.264931Z",
     "iopub.status.idle": "2024-12-05T01:15:20.972237Z",
     "shell.execute_reply": "2024-12-05T01:15:20.964691Z",
     "shell.execute_reply.started": "2024-12-05T01:13:37.265508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "# Initialize a list to hold samples from each file\n",
    "samples = []\n",
    "# Load a sample from each file\n",
    "for i in range(10):\n",
    "#for i in [7]:\n",
    "    file_path = f\"/Users/apple/Masters/Job/kaggle/jane-street-real-time-market-data-forecasting/train.parquet/partition_id={i}/part-0.parquet\"\n",
    "    chunk = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Take a sample of the data (adjust sample size as needed)\n",
    "    #sample_chunk = chunk.sample(n=500000, random_state=42)  # For example, 100 rows\n",
    "    sample_chunk = chunk[:500000]\n",
    "    samples.append(sample_chunk)\n",
    "# Concatenate all samples into one DataFrame if needed\n",
    "del chunk\n",
    "gc.collect()  # Forces garbage collection\n",
    "sample_df = pd.concat(samples, ignore_index=True)\n",
    "del samples\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:15:20.980705Z",
     "iopub.status.busy": "2024-12-05T01:15:20.98005Z",
     "iopub.status.idle": "2024-12-05T01:15:21.044985Z",
     "shell.execute_reply": "2024-12-05T01:15:21.042794Z",
     "shell.execute_reply.started": "2024-12-05T01:15:20.980645Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_00</th>\n",
       "      <th>feature_01</th>\n",
       "      <th>feature_02</th>\n",
       "      <th>feature_03</th>\n",
       "      <th>feature_04</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>responder_0</th>\n",
       "      <th>responder_1</th>\n",
       "      <th>responder_2</th>\n",
       "      <th>responder_3</th>\n",
       "      <th>responder_4</th>\n",
       "      <th>responder_5</th>\n",
       "      <th>responder_6</th>\n",
       "      <th>responder_7</th>\n",
       "      <th>responder_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.889038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281498</td>\n",
       "      <td>0.738489</td>\n",
       "      <td>-0.069556</td>\n",
       "      <td>1.380875</td>\n",
       "      <td>2.005353</td>\n",
       "      <td>0.186018</td>\n",
       "      <td>1.218368</td>\n",
       "      <td>0.775981</td>\n",
       "      <td>0.346999</td>\n",
       "      <td>0.095504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.370613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302441</td>\n",
       "      <td>2.965889</td>\n",
       "      <td>1.190077</td>\n",
       "      <td>-0.523998</td>\n",
       "      <td>3.849921</td>\n",
       "      <td>2.626981</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.703665</td>\n",
       "      <td>0.216683</td>\n",
       "      <td>0.778639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.285698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.056285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096792</td>\n",
       "      <td>-0.864488</td>\n",
       "      <td>-0.280303</td>\n",
       "      <td>-0.326697</td>\n",
       "      <td>0.375781</td>\n",
       "      <td>1.271291</td>\n",
       "      <td>0.099793</td>\n",
       "      <td>2.109352</td>\n",
       "      <td>0.670881</td>\n",
       "      <td>0.772828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.690606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.139366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>0.408499</td>\n",
       "      <td>0.223992</td>\n",
       "      <td>2.294888</td>\n",
       "      <td>1.097444</td>\n",
       "      <td>1.225872</td>\n",
       "      <td>1.225376</td>\n",
       "      <td>1.114137</td>\n",
       "      <td>0.775199</td>\n",
       "      <td>-1.379516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.440570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955200</td>\n",
       "      <td>...</td>\n",
       "      <td>3.418133</td>\n",
       "      <td>-0.373387</td>\n",
       "      <td>-0.502764</td>\n",
       "      <td>-0.348021</td>\n",
       "      <td>-3.928148</td>\n",
       "      <td>-1.591366</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-3.572820</td>\n",
       "      <td>-1.089123</td>\n",
       "      <td>-5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_id  time_id  symbol_id    weight  feature_00  feature_01  feature_02  \\\n",
       "0        0        0          1  3.889038         NaN         NaN         NaN   \n",
       "1        0        0          7  1.370613         NaN         NaN         NaN   \n",
       "2        0        0          9  2.285698         NaN         NaN         NaN   \n",
       "3        0        0         10  0.690606         NaN         NaN         NaN   \n",
       "4        0        0         14  0.440570         NaN         NaN         NaN   \n",
       "\n",
       "   feature_03  feature_04  feature_05  ...  feature_78  responder_0  \\\n",
       "0         NaN         NaN    0.851033  ...   -0.281498     0.738489   \n",
       "1         NaN         NaN    0.676961  ...   -0.302441     2.965889   \n",
       "2         NaN         NaN    1.056285  ...   -0.096792    -0.864488   \n",
       "3         NaN         NaN    1.139366  ...   -0.296244     0.408499   \n",
       "4         NaN         NaN    0.955200  ...    3.418133    -0.373387   \n",
       "\n",
       "   responder_1  responder_2  responder_3  responder_4  responder_5  \\\n",
       "0    -0.069556     1.380875     2.005353     0.186018     1.218368   \n",
       "1     1.190077    -0.523998     3.849921     2.626981     5.000000   \n",
       "2    -0.280303    -0.326697     0.375781     1.271291     0.099793   \n",
       "3     0.223992     2.294888     1.097444     1.225872     1.225376   \n",
       "4    -0.502764    -0.348021    -3.928148    -1.591366    -5.000000   \n",
       "\n",
       "   responder_6  responder_7  responder_8  \n",
       "0     0.775981     0.346999     0.095504  \n",
       "1     0.703665     0.216683     0.778639  \n",
       "2     2.109352     0.670881     0.772828  \n",
       "3     1.114137     0.775199    -1.379516  \n",
       "4    -3.572820    -1.089123    -5.000000  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:15:21.050366Z",
     "iopub.status.busy": "2024-12-05T01:15:21.0498Z",
     "iopub.status.idle": "2024-12-05T01:15:43.97262Z",
     "shell.execute_reply": "2024-12-05T01:15:43.971072Z",
     "shell.execute_reply.started": "2024-12-05T01:15:21.050317Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 18:32:07.831769: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "# Separate features and responders\n",
    "features = sample_df.filter(regex='^feature_')\n",
    "responders = sample_df.filter(regex='^responder_')\n",
    "weights = sample_df['weight']\n",
    "# Convert to numpy arrays for TensorFlow\n",
    "X = features.values  # Features for input\n",
    "#y = responders.values  # Responders for output\n",
    "# Assuming you have a DataFrame `y_train` with all responders\n",
    "y = responders[['responder_6']].values  # Keep only responder_6\n",
    "X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:15:43.977804Z",
     "iopub.status.busy": "2024-12-05T01:15:43.976773Z",
     "iopub.status.idle": "2024-12-05T01:15:43.986118Z",
     "shell.execute_reply": "2024-12-05T01:15:43.983872Z",
     "shell.execute_reply.started": "2024-12-05T01:15:43.977744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Is_keras = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:15:43.988157Z",
     "iopub.status.busy": "2024-12-05T01:15:43.987732Z",
     "iopub.status.idle": "2024-12-05T01:15:44.011901Z",
     "shell.execute_reply": "2024-12-05T01:15:44.010175Z",
     "shell.execute_reply.started": "2024-12-05T01:15:43.988117Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (4000000, 79), (4000000, 1), (4000000,)\n",
      "Validation shapes: (1000000, 79), (1000000, 1), (1000000,)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(X) * 0.8)\n",
    "\n",
    "# Sequential split\n",
    "X_train = X[:train_size]\n",
    "X_val = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_val = y[train_size:]\n",
    "weights_train = weights[:train_size]\n",
    "weights_val = weights[train_size:]\n",
    "\n",
    "print(f\"Train shapes: {X_train.shape}, {y_train.shape}, {weights_train.shape}\")\n",
    "print(f\"Validation shapes: {X_val.shape}, {y_val.shape}, {weights_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Autoencoder for compact representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:15:44.015293Z",
     "iopub.status.busy": "2024-12-05T01:15:44.014094Z",
     "iopub.status.idle": "2024-12-05T01:21:32.307176Z",
     "shell.execute_reply": "2024-12-05T01:21:32.305856Z",
     "shell.execute_reply.started": "2024-12-05T01:15:44.015232Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,240</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,191</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m79\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m10,240\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bottleneck (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m2,112\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m8,320\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m79\u001b[0m)             â”‚        \u001b[38;5;34m10,191\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,199</span> (160.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,199\u001b[0m (160.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,199</span> (160.93 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,199\u001b[0m (160.93 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125000/125000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1ms/step - loss: 0.2611 - val_loss: 0.1243 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# Define the Autoencoder model\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "latent_dim = 32  # Dimension of the bottleneck layer\n",
    "encoder_input = layers.Input(shape=(input_dim,))\n",
    "x = layers.Dense(128, activation='relu')(encoder_input)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "bottleneck = layers.Dense(latent_dim, activation='linear', name='bottleneck')(x)  # Encoder output\n",
    "# Decoder\n",
    "x = layers.Dense(64, activation='relu')(bottleneck)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "decoder_output = layers.Dense(input_dim, activation='linear')(x)\n",
    "autoencoder = models.Model(encoder_input, decoder_output, name=\"Autoencoder\")\n",
    "# Compile the Autoencoder\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "autoencoder.summary()\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, min_delta = 0.00001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6)\n",
    "# Train the Autoencoder\n",
    "history = autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    validation_data=(X_val, X_val),\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "# Extract the encoder\n",
    "encoder = models.Model(encoder_input, bottleneck, name=\"Encoder\")\n",
    "encoder.save(\"/Users/apple/Masters/Job/kaggle/jane-street-real-time-market-data-forecasting/Beginner.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "See [Feature engineering, xgboost](https://www.kaggle.com/code/dlarionov/feature-engineering-xgboost#Part-2,-xgboost) and [ğŸ¥‡ğŸ¥‡Jane Street Baseline lgb, xgb and catboostğŸ¥‡ğŸ¥‡](https://www.kaggle.com/code/yuanzhezhou/jane-street-baseline-lgb-xgb-and-catboost)for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:21:32.309622Z",
     "iopub.status.busy": "2024-12-05T01:21:32.309218Z",
     "iopub.status.idle": "2024-12-05T01:21:32.315746Z",
     "shell.execute_reply": "2024-12-05T01:21:32.314373Z",
     "shell.execute_reply.started": "2024-12-05T01:21:32.309576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define a learning rate schedule\n",
    "def learning_rate_scheduler_xgb(epoch):\n",
    "    initial_rate = 0.3\n",
    "    decay_rate = 0.999\n",
    "    return initial_rate * (decay_rate ** (np.log(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:21:32.317685Z",
     "iopub.status.busy": "2024-12-05T01:21:32.317243Z",
     "iopub.status.idle": "2024-12-05T01:22:19.875268Z",
     "shell.execute_reply": "2024-12-05T01:22:19.874035Z",
     "shell.execute_reply.started": "2024-12-05T01:21:32.317583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# Create an XGBoost model\n",
    "model_xgb = XGBRegressor(\n",
    "    n_estimators=5000,\n",
    "    learning_rate=learning_rate_scheduler_xgb,\n",
    "    tree_method='hist',\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "# Fit the model with sample weights and validation dataset\n",
    "model_xgb.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    " #   sample_weight=weights_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "#    sample_weight_eval_set=[weights_train, weights_val],\n",
    "    eval_metric='rmse',\n",
    "    early_stopping_rounds=10,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:22:19.877458Z",
     "iopub.status.busy": "2024-12-05T01:22:19.876796Z",
     "iopub.status.idle": "2024-12-05T01:22:20.142476Z",
     "shell.execute_reply": "2024-12-05T01:22:20.141645Z",
     "shell.execute_reply.started": "2024-12-05T01:22:19.877418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred = model_xgb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:22:20.146794Z",
     "iopub.status.busy": "2024-12-05T01:22:20.146342Z",
     "iopub.status.idle": "2024-12-05T01:22:20.167658Z",
     "shell.execute_reply": "2024-12-05T01:22:20.166017Z",
     "shell.execute_reply.started": "2024-12-05T01:22:20.146742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f\"RMSE: {mse}\")\n",
    "print(f\"RÂ²: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:22:20.169834Z",
     "iopub.status.busy": "2024-12-05T01:22:20.169302Z",
     "iopub.status.idle": "2024-12-05T01:22:20.18461Z",
     "shell.execute_reply": "2024-12-05T01:22:20.183631Z",
     "shell.execute_reply.started": "2024-12-05T01:22:20.169783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Save the model\n",
    "joblib.dump(model_xgb, \"xgboost_sklearn.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Autoencoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Centralization for Better Training Performance\n",
    "\n",
    "See https://keras.io/examples/vision/gradient_centralization/ for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:22:20.187276Z",
     "iopub.status.busy": "2024-12-05T01:22:20.186455Z",
     "iopub.status.idle": "2024-12-05T01:22:20.207282Z",
     "shell.execute_reply": "2024-12-05T01:22:20.205176Z",
     "shell.execute_reply.started": "2024-12-05T01:22:20.187221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "class GCRMSprop(RMSprop):\n",
    "    def get_gradients(self, loss, params):\n",
    "        # We here just provide a modified get_gradients() function since we are\n",
    "        # trying to just compute the centralized gradients.\n",
    "        grads = []\n",
    "        gradients = super().get_gradients()\n",
    "        for grad in gradients:\n",
    "            grad_len = len(grad.shape)\n",
    "            if grad_len > 1:\n",
    "                axis = list(range(grad_len - 1))\n",
    "                grad -= ops.mean(grad, axis=axis, keep_dims=True)\n",
    "            grads.append(grad)\n",
    "        return grads\n",
    "optimizer = GCRMSprop(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:22:20.209737Z",
     "iopub.status.busy": "2024-12-05T01:22:20.209105Z",
     "iopub.status.idle": "2024-12-05T01:22:20.272754Z",
     "shell.execute_reply": "2024-12-05T01:22:20.271066Z",
     "shell.execute_reply.started": "2024-12-05T01:22:20.209683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "# Define the number of input and output nodes\n",
    "input_dim = X.shape[1]  # Number of features (79)\n",
    "output_dim = y.shape[1]  # Number of responders (9)\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(input_dim,)), # Input layer\n",
    "   # layers.LayerNormalization(),\n",
    "   # layers.BatchNormalization(),\n",
    "  #  layers.Dense(128, activation='relu'),\n",
    "  #  layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='linear'),  # Encoder\n",
    "    layers.Dense(32, activation='gelu'),  # Bottleneck layer (compression)\n",
    "    layers.Dense(output_dim, activation='linear'),  # Decoder\n",
    "#    layers.Dense(128, activation='relu'), \n",
    "    layers.Dropout(0.2)#,\n",
    "#    layers.Dense(output_dim, activation='linear'#, kernel_regularizer=l2(0.001))  # Output layer for responders\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:22:20.27439Z",
     "iopub.status.busy": "2024-12-05T01:22:20.274017Z",
     "iopub.status.idle": "2024-12-05T01:22:20.280236Z",
     "shell.execute_reply": "2024-12-05T01:22:20.278925Z",
     "shell.execute_reply.started": "2024-12-05T01:22:20.274354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def step_decay(epoch):\n",
    "    initial_lr = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 5\n",
    "    lr = initial_lr * (drop ** (epoch // epochs_drop))\n",
    "    return lr\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:22:20.283112Z",
     "iopub.status.busy": "2024-12-05T01:22:20.282216Z",
     "iopub.status.idle": "2024-12-05T01:22:20.298522Z",
     "shell.execute_reply": "2024-12-05T01:22:20.297358Z",
     "shell.execute_reply.started": "2024-12-05T01:22:20.283061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:22:20.30098Z",
     "iopub.status.busy": "2024-12-05T01:22:20.300444Z",
     "iopub.status.idle": "2024-12-05T01:22:20.318766Z",
     "shell.execute_reply": "2024-12-05T01:22:20.317504Z",
     "shell.execute_reply.started": "2024-12-05T01:22:20.300909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Monitor validation loss\n",
    "    patience=10,            # Number of epochs to wait for improvement\n",
    "    min_delta=0.00001,       # Minimum change to qualify as an improvement\n",
    "    restore_best_weights=True  # Restore weights from the best epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T01:22:20.321104Z",
     "iopub.status.busy": "2024-12-05T01:22:20.320548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if Is_keras:\n",
    "    history = model.fit(\n",
    "    X_train, y_train,\n",
    "   # sample_weight=weights_train,  # Training sample weights\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val#, \n",
    "                     #weights_val\n",
    "                    ),  # Validation data with sample weights\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if Is_keras:\n",
    "    model.save(\"/kaggle/working/model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "See [Jane Street RMF Demo Submission](https://www.kaggle.com/code/ryanholbrook/jane-street-rmf-demo-submission) for details.\n",
    "\n",
    "Depending on the size of your training set, you will need an [inference notebook](https://www.kaggle.com/code/regisvargas/inference-jane-street-a-beginner-s-notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import kaggle_evaluation.jane_street_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "# Assuming `model` is your trained model\n",
    "# Assuming features required by the model are named 'feature_00', 'feature_01', etc.\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "    global lags_\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "    # Extract the features for the model input\n",
    "    feature_columns = [col for col in test.columns if col.startswith(\"feature_\")]\n",
    "    features = test.select(feature_columns).to_numpy()  # Convert to numpy array for model input\n",
    "    features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    # Generate predictions using the model\n",
    "    #model_predictions = model.predict(features)\n",
    "    if Is_keras:\n",
    "        responder_6_predictions = model.predict(features)[:,0]\n",
    "    else:\n",
    "        responder_6_predictions = model_xgb.predict(features)\n",
    "   # print(responder_6_predictions)    \n",
    "    #responder_6_predictions = model_predictions[:, 6]  # Assuming responder_6 is at index 6\n",
    "    # Create a new Polars DataFrame with row_id and responder_6 predictions\n",
    "    predictions = test.select(\"row_id\").with_columns(\n",
    "        pl.Series(\"responder_6\", responder_6_predictions)\n",
    "    )\n",
    "    print(predictions)\n",
    "    # Ensure the output format and length requirements\n",
    "    if isinstance(predictions, pl.DataFrame):\n",
    "        assert predictions.columns == ['row_id', 'responder_6']\n",
    "    elif isinstance(predictions, pd.DataFrame):\n",
    "        assert (predictions.columns == ['row_id', 'responder_6']).all()\n",
    "    else:\n",
    "        raise TypeError('The predict function must return a DataFrame')\n",
    "    \n",
    "    assert len(predictions) == len(test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11305158,
     "sourceId": 84493,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "quant2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
